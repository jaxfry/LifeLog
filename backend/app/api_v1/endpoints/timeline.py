import uuid
import logging
from typing import List, Optional, Annotated
from datetime import date, datetime # datetime needed for query params
import duckdb
from fastapi import APIRouter, Depends, HTTPException, status, Query

from backend.app import schemas
from backend.app.api_v1.deps import get_db, get_db_writable # Import new dependency
from backend.app.api_v1.auth import get_current_active_user
from backend.app.api_v1.endpoints.projects import ProjectRepository
from backend.app.core.utils import with_db_write_retry

router = APIRouter()
logger = logging.getLogger(__name__)

CurrentUserDep = Annotated[schemas.User, Depends(get_current_active_user)]
DBDep = Annotated[duckdb.DuckDBPyConnection, Depends(get_db)] # For read-only connections
DBWritableDep = Annotated[duckdb.DuckDBPyConnection, Depends(get_db_writable)] # For read-write connections

# --- Helper to map DB row to TimelineEntry schema, including project ---
def _map_timeline_entry_row_to_schema(db: duckdb.DuckDBPyConnection, row: tuple) -> Optional[schemas.TimelineEntry]:
    if not row:
        return None
    
    entry_id, start_time, end_time, title, summary, project_id_db, local_day_db = row
    
    project_schema: Optional[schemas.Project] = None
    if project_id_db:
        try:
            project_repo = ProjectRepository(db)
            project_schema = project_repo.get_project_by_id(project_id_db)
        except Exception as e:
            logger.warning(f"Failed to fetch project {project_id_db}: {e}")
            # Continue without the project data rather than failing completely

    return schemas.TimelineEntry(
        id=entry_id,
        start_time=start_time,
        end_time=end_time,
        title=title,
        summary=summary,
        project_id=project_id_db, # Keep original project_id
        local_day=local_day_db,   # Already a date from DB via GENERATED ALWAYS AS
        project=project_schema    # Populated project details
    )

# --- CRUD Operations for Timeline Entries ---

@with_db_write_retry()
def create_timeline_entry_db(db: duckdb.DuckDBPyConnection, entry: schemas.TimelineEntryCreate) -> Optional[schemas.TimelineEntry]:
    entry_id = uuid.uuid4()
    # local_day is generated by the DB, so no need to insert it explicitly.
    # source_event_ids handling:
    # This requires inserting into timeline_entries and then timeline_source_events if source_event_ids are provided.
    # This should be done in a transaction.
    
    try:
        db.begin() # Start transaction
        db.execute(
            "INSERT INTO timeline_entries (id, start_time, end_time, title, summary, project_id) VALUES (?, ?, ?, ?, ?, ?)",
            [str(entry_id), entry.start_time, entry.end_time, entry.title, entry.summary, str(entry.project_id) if entry.project_id else None]
        )
        
        if entry.source_event_ids:
            for event_id in entry.source_event_ids:
                # TODO: Add validation to ensure these event_ids exist in the 'events' table
                # For now, assuming valid IDs are provided.
                db.execute(
                    "INSERT INTO timeline_source_events (entry_id, event_id) VALUES (?, ?)",
                    [str(entry_id), str(event_id)]
                )
        db.commit() # Commit transaction
        
        # Fetch the created entry to return it with populated project and local_day
        created_entry_row = db.execute(
            "SELECT id, start_time, end_time, title, summary, project_id, local_day FROM timeline_entries WHERE id = ?",
            [str(entry_id)]
        ).fetchone()
        if created_entry_row:
            return _map_timeline_entry_row_to_schema(db, created_entry_row)
        return None # Should ideally not happen if insert was successful
        
    except duckdb.Error as e:
        db.rollback() # Rollback on error
        # Log error e
        # Check for foreign key violation if project_id is invalid
        if "FOREIGN KEY constraint failed" in str(e) and entry.project_id:
             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Invalid project_id: {entry.project_id}. Project does not exist.")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Could not create timeline entry: {e}")


def get_timeline_entry_db(db: duckdb.DuckDBPyConnection, entry_id: uuid.UUID) -> Optional[schemas.TimelineEntry]:
    try:
        entry_row = db.execute(
            "SELECT id, start_time, end_time, title, summary, project_id, local_day FROM timeline_entries WHERE id = ?",
            [str(entry_id)]
        ).fetchone()
        if entry_row:
            return _map_timeline_entry_row_to_schema(db, entry_row)
        return None
    except (duckdb.Error, Exception) as e:
        logger.error(f"Error fetching timeline entry {entry_id}: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Database query failed")


def get_timeline_entries_db(
    db: duckdb.DuckDBPyConnection,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    project_id: Optional[uuid.UUID] = None,
    skip: int = 0,
    limit: int = 20,
    sort_by: str = "start_time",
    order: str = "desc"
) -> List[schemas.TimelineEntry]:
    
    # Validate connection health
    try:
        db.execute("SELECT 1").fetchone()
    except Exception as e:
        logger.error(f"Database connection unhealthy: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Database connection failed")
    
    query = "SELECT id, start_time, end_time, title, summary, project_id, local_day FROM timeline_entries"
    conditions = []
    params = []

    if start_date:
        conditions.append("local_day >= ?")
        params.append(start_date)
    if end_date:
        conditions.append("local_day <= ?")
        params.append(end_date)
    if project_id:
        conditions.append("project_id = ?")
        params.append(str(project_id))

    if conditions:
        query += " WHERE " + " AND ".join(conditions)

    valid_sort_fields = ["start_time", "end_time", "title", "local_day"]
    if sort_by not in valid_sort_fields:
        sort_by = "start_time" # Default sort
    
    valid_order = ["asc", "desc"]
    if order.lower() not in valid_order:
        order = "desc" # Default order

    query += f" ORDER BY {sort_by} {order.upper()}"
    query += " LIMIT ? OFFSET ?"
    params.extend([limit, skip])

    try:
        logger.debug(f"Executing timeline query: {query} with params: {params}")
        entry_rows = db.execute(query, params).fetchall()
    except (duckdb.Error, Exception) as e:
        logger.error(f"Error executing timeline query: {e}")
        logger.error(f"Query was: {query}")
        logger.error(f"Params were: {params}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Database query failed")
    # Ensure no None values are passed to the final list if _map_timeline_entry_row_to_schema could return None
    # (though it shouldn't if 'row' itself is valid)
    # The `if row` in the original comprehension already guards against None rows from fetchall.
    # The main concern is if _map_timeline_entry_row_to_schema itself returns None for a valid row,
    # which it shouldn't based on its current logic.
    # However, to be absolutely type-safe for the return List[schemas.TimelineEntry]:
    results = []
    for row in entry_rows:
        if row: # Should always be true as fetchall() gives list of tuples
            mapped_entry = _map_timeline_entry_row_to_schema(db, row)
            if mapped_entry: # Add only if mapping is successful
                results.append(mapped_entry)
    return results

@with_db_write_retry()
def update_timeline_entry_db(
    db: duckdb.DuckDBPyConnection, entry_id: uuid.UUID, entry_update: schemas.TimelineEntryUpdate
) -> Optional[schemas.TimelineEntry]:
    existing_entry = get_timeline_entry_db(db, entry_id)
    if not existing_entry:
        return None

    update_data = entry_update.model_dump(exclude_unset=True)
    if not update_data:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="No fields to update.")

    set_clauses = []
    params = []

    for key, value in update_data.items():
        if key == "source_event_ids": # Handle separately after main update
            continue
        if key == "project_id" and value is not None:
             # Validate project_id exists before updating
            project_repo = ProjectRepository(db)
            if not project_repo.get_project_by_id(value):
                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Invalid project_id: {value}. Project does not exist.")
            set_clauses.append(f"{key} = ?")
            params.append(str(value))
        elif value is not None : # Allow setting project_id to null
            set_clauses.append(f"{key} = ?")
            params.append(value)


    if not set_clauses and "source_event_ids" not in update_data: # if only source_event_ids or nothing
        # If only source_event_ids, we still need to proceed. If nothing, it's already handled.
        pass
    
    try:
        db.begin()
        if set_clauses:
            query = f"UPDATE timeline_entries SET {', '.join(set_clauses)} WHERE id = ?"
            params.append(str(entry_id))
            db.execute(query, params)

        # Handle source_event_ids: delete existing and insert new ones
        if "source_event_ids" in update_data:
            db.execute("DELETE FROM timeline_source_events WHERE entry_id = ?", [str(entry_id)])
            if update_data["source_event_ids"]: # If not None or empty list
                for event_id in update_data["source_event_ids"]:
                    # TODO: Validate event_id exists
                    db.execute(
                        "INSERT INTO timeline_source_events (entry_id, event_id) VALUES (?, ?)",
                        [str(entry_id), str(event_id)]
                    )
        db.commit()
    except duckdb.Error as e:
        db.rollback()
        # Log error e
        if "FOREIGN KEY constraint failed" in str(e) and "project_id" in update_data:
             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Invalid project_id in update. Project does not exist.")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Could not update timeline entry: {e}")

    return get_timeline_entry_db(db, entry_id)

@with_db_write_retry()
def delete_timeline_entry_db(db: duckdb.DuckDBPyConnection, entry_id: uuid.UUID) -> bool:
    existing_entry = get_timeline_entry_db(db, entry_id)
    if not existing_entry:
        return False
    try:
        db.begin()
        # Delete from timeline_source_events first due to potential FK constraints
        db.execute("DELETE FROM timeline_source_events WHERE entry_id = ?", [str(entry_id)])
        db.execute("DELETE FROM timeline_entries WHERE id = ?", [str(entry_id)])
        db.commit()
        return True
    except duckdb.Error as e:
        db.rollback()
        # Log error e
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Could not delete timeline entry: {e}")

# --- API Endpoints ---

@router.post("", response_model=schemas.TimelineEntry, status_code=status.HTTP_201_CREATED)
def create_timeline_entry(
    entry_in: schemas.TimelineEntryCreate,
    db: DBWritableDep, # Use writable DB for creation
    current_user: CurrentUserDep
):
    """
    Create a new timeline entry.
    `local_day` is automatically derived from `start_time`.
    If `project_id` is provided, it must correspond to an existing project.
    `source_event_ids` can link this timeline entry to raw events.
    """
    created_entry = create_timeline_entry_db(db, entry_in)
    # create_timeline_entry_db raises HTTPException on failure
    return created_entry

@router.get("", response_model=List[schemas.TimelineEntry])
def read_timeline_entries(
    db: DBDep,
    current_user: CurrentUserDep,
    start_date: Optional[date] = Query(None, description="Filter by start date (YYYY-MM-DD). Inclusive."),
    end_date: Optional[date] = Query(None, description="Filter by end date (YYYY-MM-DD). Inclusive."),
    project_id: Optional[uuid.UUID] = Query(None, description="Filter by project ID."),
    skip: int = Query(0, ge=0, description="Number of items to skip."),
    limit: int = Query(20, ge=1, le=200, description="Number of items to return."),
    sort_by: str = Query("start_time", enum=["start_time", "end_time", "title", "local_day"], description="Field to sort by."),
    order: str = Query("desc", enum=["asc", "desc"], description="Sort order (asc or desc).")
):
    """
    Retrieve timeline entries with filtering, sorting, and pagination.
    """
    entries = get_timeline_entries_db(db, start_date, end_date, project_id, skip, limit, sort_by, order)
    return entries

@router.get("/{entry_id}", response_model=schemas.TimelineEntry)
def read_timeline_entry(
    entry_id: uuid.UUID,
    db: DBDep,
    current_user: CurrentUserDep
):
    """
    Get a specific timeline entry by its ID.
    """
    db_entry = get_timeline_entry_db(db, entry_id)
    if db_entry is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Timeline entry not found")
    return db_entry

@router.put("/{entry_id}", response_model=schemas.TimelineEntry)
def update_timeline_entry(
    entry_id: uuid.UUID,
    entry_in: schemas.TimelineEntryUpdate,
    db: DBWritableDep, # Use writable DB for update
    current_user: CurrentUserDep
):
    """
    Update an existing timeline entry.
    Allows partial updates. If `project_id` is updated, it must exist.
    `source_event_ids` will replace any existing linked events for this entry.
    """
    updated_entry = update_timeline_entry_db(db, entry_id, entry_in)
    if updated_entry is None: # Means entry was not found initially
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Timeline entry not found")
    return updated_entry

@router.delete("/{entry_id}", status_code=status.HTTP_204_NO_CONTENT)
def delete_timeline_entry(
    entry_id: uuid.UUID,
    db: DBWritableDep, # Use writable DB for deletion
    current_user: CurrentUserDep
):
    """
    Delete a timeline entry.
    This will also remove its associations from `timeline_source_events`.
    """
    if not delete_timeline_entry_db(db, entry_id): # Handles not found case internally now
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Timeline entry not found")
    return # FastAPI handles 204 No Content